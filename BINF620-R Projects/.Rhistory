library(tidyr)
library(VIM)
library(naivebayes)
library(MASS)
set.seed(30)
# Split Data
trainIndex <- createDataPartition(imputedALIVE$BF5EVER, p = 0.7, list = FALSE, times = 1)
data_trn <- imputedALIVE[trainIndex, ]
data_tst <- imputedALIVE[-trainIndex, ]
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
# Predict
data_trn_pred <- predict(alive_lda, data_trn)$BF5EVER
data_tst_pred <- predict(alive_lda, data_tst)$BF5EVER
#We store the predictions made on the train and test sets.
calc_class_err = function(actual, predicted) {
mean(actual != predicted)
}
calc_class_err(predicted = data_trn_pred, actual = data_trn$BF5EVER)
calc_class_err(predicted = data_tst_pred, actual = data_tst$BF5EVER)
View(alive_lda)
# Split Data
trainIndex <- createDataPartition(imputedALIVE$BF5EVER, p = 0.7, list = FALSE, times = 1)
data_trn <- imputedALIVE[trainIndex, ]
data_tst <- imputedALIVE[-trainIndex, ]
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
# Predict
data_trn_pred <- predict(alive_lda, data_trn$BF5EVER)
# Split Data
trainIndex <- createDataPartition(imputedALIVE$BF5EVER, p = 0.7, list = FALSE, times = 1)
data_trn <- imputedALIVE[trainIndex, ]
data_tst <- imputedALIVE[-trainIndex, ]
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
# Predict
data_trn_pred <- predict(alive_lda, data_trn)
data_tst_pred <- predict(alive_lda, data_tst)
#We store the predictions made on the train and test sets.
calc_class_err = function(actual, predicted) {
mean(actual != predicted)
}
calc_class_err(predicted = data_trn_pred, actual = data_trn$BF5EVER)
# Split Data
trainIndex <- createDataPartition(imputedALIVE$BF5EVER, p = 0.7, list = FALSE, times = 1)
data_trn <- imputedALIVE[trainIndex, ]
data_tst <- imputedALIVE[-trainIndex, ]
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
# Predict
data_trn_pred <- predict(alive_lda, data_trn)
data_tst_pred <- predict(alive_lda, data_tst)
#We store the predictions made on the train and test sets.
calc_class_err = function(actual, predicted) {
mean(actual != predicted)
}
calc_class_err(predicted = data_trn_pred, actual = data_trn)
alive_lda
# Model Tables
alive_lda$tables
View(alive_lda)
View(naive_model)
# Model Tables
alive_lda$terms
alive_lda$counts
alive_lda$counts
alive_lda$means
# Split Data
trainIndex <- createDataPartition(imputedALIVE$BF5EVER, p = 0.7, list = FALSE, times = 1)
data_trn <- imputedALIVE[trainIndex, ]
data_tst <- imputedALIVE[-trainIndex, ]
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
# Predict
data_trn_pred <- predict(alive_lda, data_trn)
data_tst_pred <- predict(alive_lda, data_tst)
#We store the predictions made on the train and test sets.
calc_class_err = function(actual, predicted) {
mean(actual != predicted)
}
# Check accuracy
accuracy_lda <- mean(data_trn_pred$BF5EVER == data_tst_pred)
conf_matrix_lda <- table(data_trn_pred$BF5EVER, data_tst_pred)
# Split Data
trainIndex <- createDataPartition(imputedALIVE$BF5EVER, p = 0.7, list = FALSE, times = 1)
data_trn <- imputedALIVE[trainIndex, ]
data_tst <- imputedALIVE[-trainIndex, ]
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
# Predict
data_trn_pred <- predict(alive_lda, data_trn)
data_tst_pred <- predict(alive_lda, data_tst)
#We store the predictions made on the train and test sets.
calc_class_err = function(actual, predicted) {
mean(actual != predicted)
}
# Check accuracy
accuracy_lda <- mean(data_trn_pred$BF5EVER == data_tst_pred)
conf_matrix_lda <- table(data_trn_pred, data_tst_pred)
# Split Data
trainIndex <- createDataPartition(imputedALIVE$BF5EVER, p = 0.7, list = FALSE, times = 1)
data_trn <- imputedALIVE[trainIndex, ]
data_tst <- imputedALIVE[-trainIndex, ]
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
# Predict
data_trn_pred <- predict(alive_lda, data_trn)
data_tst_pred <- predict(alive_lda, data_tst)
# Store Predictions
predictions_tst <- data_tst_pred$BF5EVER
predictions_trn <- data_trn_pred$BF5EVER
# Calculate classification error
calc_class_err <- function(actual, predicted) {
mean(actual != predicted)
}
# Check accuracy on the training set
accuracy_trn <- mean(predictions_trn == data_trn$BF5EVER)
# Check accuracy on the test set
accuracy_tst <- mean(predictions_tst == data_tst$BF5EVER)
# Create confusion matrices
conf_matrix_trn <- table(predictions_trn, data_trn$BF5EVER)
# Split Data
trainIndex <- createDataPartition(imputedALIVE$BF5EVER, p = 0.7, list = FALSE, times = 1)
data_trn <- imputedALIVE[trainIndex, ]
data_tst <- imputedALIVE[-trainIndex, ]
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
# Predict
data_trn_pred <- predict(alive_lda, data_trn)
data_tst_pred <- predict(alive_lda, data_tst)
# Store Predictions
predictions_trn <- data_trn_pred$class
predictions_tst <- data_tst_pred$class
# Calculate classification error
calc_class_err <- function(actual, predicted) {
mean(actual != predicted)
}
# Check accuracy on the training set
accuracy_trn <- mean(predictions_trn == data_trn$BF5EVER)
# Check accuracy on the test set
accuracy_tst <- mean(predictions_tst == data_tst$BF5EVER)
# Create confusion matrices
conf_matrix_trn <- table(predictions_trn, data_trn$BF5EVER)
conf_matrix_tst <- table(predictions_tst, data_tst$BF5EVER)
# Output results
accuracy_trn
conf_matrix_trn
accuracy_tst
conf_matrix_tst
# Split Data
trainIndex <- createDataPartition(imputedALIVE$BF5EVER, p = 0.7, list = FALSE, times = 1)
data_trn <- imputedALIVE[trainIndex, ]
data_tst <- imputedALIVE[-trainIndex, ]
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
alive_lda
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
alive_lda
alive_lda$prior
alive_lda$counts
alive_lda$means
# Predict
data_trn_pred <- predict(alive_lda, data_trn)
data_tst_pred <- predict(alive_lda, data_tst)
# Store Predictions
predictions_trn <- data_trn_pred$class
predictions_tst <- data_tst_pred$class
# Calculate classification error
calc_class_err <- function(actual, predicted) {
mean(actual != predicted)
}
# Check accuracy on the training set
accuracy_trn <- mean(predictions_trn == data_trn$BF5EVER)
# Check accuracy on the test set
accuracy_tst <- mean(predictions_tst == data_tst$BF5EVER)
# Create confusion matrices
conf_matrix_trn <- table(predictions_trn, data_trn$BF5EVER)
conf_matrix_tst <- table(predictions_tst, data_tst$BF5EVER)
# Output results
accuracy_trn
conf_matrix_trn
accuracy_tst
conf_matrix_tst
alive_lda$counts
kable(alive_lda$means, caption = "Group Means", format = "html")
kable(alive_lda$counts, caption = "Counts", format = "html")
kable(alive_lda$means, caption = "Group Means", format = "html")
coefDiscrim <- data.frame(
Variable = c("PGWT_GN", "MOM_CM", "MOM_BMI", "MOMCIG", "CIG_PRIOR", "MOM_LBKG"),
LD1 = c(0.003902853, 0.060731142, 0.083359371, -0.164828374, -0.068187890, -0.021325825)
)
kable(coefDiscrim, caption = "Coefficients of linear discriminants", format = "html")
# LDA Model
alive_lda = lda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
#alive_lda
# Predict
data_trn_pred <- predict(alive_lda, data_trn)
data_tst_pred <- predict(alive_lda, data_tst)
# Store Predictions
predictions_trn <- data_trn_pred$class
predictions_tst <- data_tst_pred$class
# Calculate classification error
calc_class_err <- function(actual, predicted) {
mean(actual != predicted)
}
# Check accuracy on the training set
accuracy_trn <- mean(predictions_trn == data_trn$BF5EVER)
# Check accuracy on the test set
accuracy_tst <- mean(predictions_tst == data_tst$BF5EVER)
# Create confusion matrices
conf_matrix_trn <- table(predictions_trn, data_trn$BF5EVER)
conf_matrix_tst <- table(predictions_tst, data_tst$BF5EVER)
# Output results
accuracy_trn
accuracy_tst
kable(conf_matrix_trn, caption = "Coefficient Matrix of Train", format = "html")
kable(conf_matrix_tst, caption = "Coefficient Matrix of Test", format = "html")
# QDA Model
alive_qda = qda(BF5EVER ~ PGWT_GN + MOM_CM + MOM_BMI + MOMCIG + CIG_PRIOR + MOM_LBKG, data = data_trn)
alive_qda
# Predict
data_trn_pred <- predict(alive_qda, data_trn)
data_tst_pred <- predict(alive_qda, data_tst)
# Store Predictions
predictions_trn <- data_trn_pred$class
predictions_tst <- data_tst_pred$class
# Calculate classification error
calc_class_err <- function(actual, predicted) {
mean(actual != predicted)
}
# Check accuracy on the training set
accuracy_trn <- mean(predictions_trn == data_trn$BF5EVER)
# Check accuracy on the test set
accuracy_tst <- mean(predictions_tst == data_tst$BF5EVER)
# Create confusion matrices
conf_matrix_trn <- table(predictions_trn, data_trn$BF5EVER)
conf_matrix_tst <- table(predictions_tst, data_tst$BF5EVER)
# Output results
accuracy_trn
accuracy_tst
kable(conf_matrix_trn, caption = "Coefficient Matrix of Train | QDA", format = "html")
kable(conf_matrix_tst, caption = "Coefficient Matrix of Test  | QDA", format = "html")
# Predict
data_trn_pred <- predict(alive_qda, data_trn)
data_tst_pred <- predict(alive_qda, data_tst)
# Store Predictions
predictions_trn <- data_trn_pred$class
predictions_tst <- data_tst_pred$class
# Calculate classification error
calc_class_err <- function(actual, predicted) {
mean(actual != predicted)
}
# Check accuracy on the training set
accuracy_trn <- mean(predictions_trn == data_trn$BF5EVER)
# Check accuracy on the test set
accuracy_tst <- mean(predictions_tst == data_tst$BF5EVER)
# Create confusion matrices
conf_matrix_trn <- table(predictions_trn, data_trn$BF5EVER)
conf_matrix_tst <- table(predictions_tst, data_tst$BF5EVER)
# Output results
accuracy_trn
accuracy_tst
conf_matrix_trn
conf_matrix_tst
#kable(conf_matrix_trn, caption = "Coefficient Matrix of Train | QDA", format = "html")
#kable(conf_matrix_tst, caption = "Coefficient Matrix of Test  | QDA", format = "html")
View(alive_qda)
kable(alive_qda$counts, caption = "Counts", format = "html")
kable(alive_qda$means, caption = "Group Means", format = "html")
data <- data.frame(
Metric = c(
"Prior Probabilities","Group Means","PGWT_GN","MOM_CM","MOM_BMI","MOMCIG","CIG_PRIOR","MOM_LBKG","Training Set Accuracy","Test Set Accuracy","Confusion Matrix (Training)","True Positives (TP)","False Positives (FP)","True Negatives (TN)","False Negatives (FN)","Confusion Matrix (Test)","True Positives (TP)","False Positives (FP)","True Negatives (TN)","False Negatives (FN)"),
LDA = c("1: 16.69%, 2: 83.31%",NA,30.39,162.58,26.77,2.29,3.97,156.23,"83.04%","83.06%",NA,1250,1606,110306,20856,NA,496,646,8969,8968
),
QDA = c(
"1: 16.69%, 2: 83.31%",NA,30.39,162.58,26.77,2.29,3.97,156.23,"81.17%","81.18%",NA,3978,6809,103497,18128,NA,1717,2934,44348,7748),stringsAsFactors = FALSE)
kable(data, caption = "Analysis Between LDA and QDA", format = "html")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
install.packages("rmarkdown")
install.packages("ggplot2")
install.packages("tidyverse")
install.packages("caret")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
install.packages("ranger")
install.packages("naivebayes")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
library(ggplot2)
install.packages("ggplot2")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
library(ggplot2)
install.packages("gtable")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
library(ggplot2)
library(ggplot2)
library(tidyverse)
detach("package:tidyverse", unload = TRUE)
install.packages("gtable")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
#library(ggplot2)
library(ggfortify)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
#library(ggplot2)
#library(ggfortify)
library("survminer")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
#library(ggplot2)
#library(ggfortify)
#library("survminer")
library(gridExtra)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
#library(ggplot2)
#library(ggfortify)
#library("survminer")
#library(gridExtra)
library(caret)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
#library(ggplot2)
#library(ggfortify)
#library("survminer")
#library(gridExtra)
#library(caret)
library(knitr)
library(corrplot)
library(mice)
library(tidyr)
library(VIM)
library(naivebayes)
library(MASS)
set.seed(30)
install.packages("gtable")
install.packages("gtable", type = "binary")
install.packages("gtable")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
library(ggplot2)
library(ggfortify)
library("survminer")
library(gridExtra)
library(caret)
library(knitr)
library(corrplot)
library(mice)
library(tidyr)
library(VIM)
library(naivebayes)
library(MASS)
set.seed(30)
# Kaplan–Meier method
km_fit <- survfit(Surv(Time, Death) ~ 1, data=p1Data)
p1Data <- read.csv("BINF620BigData-1.csv")
#View(p1Data)
# Kaplan–Meier method
km_fit <- survfit(Surv(Time, Death) ~ 1, data=p1Data)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
library(ggplot2)
library(ggfortify)
library("survminer")
library(gridExtra)
library(caret)
library(knitr)
library(corrplot)
library(mice)
library(tidyr)
library(VIM)
library(naivebayes)
library(MASS)
set.seed(30)
View(p1Data)
summary(p1Data)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(survival)
library(ranger)
library(ggplot2)
library(ggfortify)
library("survminer")
library(gridExtra)
library(tinytex)
BPdata <- read.csv("BPIntensiveZZ-2-1.csv")
#BPdata <- na.omit(BPdata)
#View(BPdata)
View(BPdata)
summary(p1Data)
p1 <- ggplot(p1Data, aes(x = as.factor(Gender))) +
geom_bar(fill = "skyblue") +
labs(x = "Gender (0 = Male, 1 = Female)", y = "Frequency", title = "Gender Frequency") +
theme_minimal()
p2 <- ggplot(p1Data, aes(y = Age)) +
geom_boxplot(fill = "lightblue") +
labs(y = "Age", title = "Boxplot of Age Distribution") +
theme_minimal()
p3 <- ggplot(p1Data, aes(x = as.factor(Gender), y = Age)) +
geom_boxplot(fill = "lightblue") +
labs(x = "Gender (0 = Male, 1 = Female)", y = "Age", title = "Age Distribution by Gender") +
theme_minimal()
grid.arrange(p1, p2, ncol = 2, nrow = 1)
summary(p1Data)
p1 <- ggplot(p1Data, aes(x = as.factor(Gender))) +
geom_bar(fill = "skyblue") +
labs(x = "Gender (0 = Male, 1 = Female)", y = "Frequency", title = "Gender Frequency") +
theme_minimal()
p2 <- ggplot(p1Data, aes(y = Age)) +
geom_boxplot(fill = "lightblue") +
labs(y = "Age", title = "Boxplot of Age Distribution") +
theme_classic()
p3 <- ggplot(p1Data, aes(x = as.factor(Gender), y = Age)) +
geom_boxplot(fill = "lightblue") +
labs(x = "Gender (0 = Male, 1 = Female)", y = "Age", title = "Age Distribution by Gender") +
theme_minimal()
grid.arrange(p1, p2, ncol = 2, nrow = 1)
summary(p1Data)
p1 <- ggplot(p1Data, aes(x = as.factor(Gender))) +
geom_bar(fill = "skyblue") +
labs(x = "Gender (0 = Male, 1 = Female)", y = "Frequency", title = "Gender Frequency") +
theme_minimal()
p2 <- ggplot(p1Data, aes(y = Age)) +
geom_boxplot(fill = "lightblue") +
labs(y = "Age", title = "Boxplot of Age Distribution") +
theme_classic() +
theme(axis.title.x = element_blank(),
axis.text.x = element_blank(),
axis.ticks.x = element_blank())
p3 <- ggplot(p1Data, aes(x = as.factor(Gender), y = Age)) +
geom_boxplot(fill = "lightblue") +
labs(x = "Gender (0 = Male, 1 = Female)", y = "Age", title = "Age Distribution by Gender") +
theme_minimal()
grid.arrange(p1, p2, ncol = 2, nrow = 1)
# Kaplan–Meier method
km_fit <- survfit(Surv(Months.of.Follow.up, Reason.of.End.the.Study) ~ 1, data=p1Data)
p1Data <- p1Data %>% rename(Event_Type = `Reason.of.End.the.Study`)
p1Data <- p1Data %>% rename(Event_type = `Reason.of.End.the.Study`)
p1Data <- read.csv("BINF620BigData-1.csv")
#View(p1Data)
p1Data <- p1Data %>% rename(Event_type = `Reason.of.End.the.Study`)
p1Data$Event <- ifelse(p1Data$Event_type == "DEATH", 1, 0)
p1Data <- read.csv("BINF620BigData-1.csv")
#View(p1Data)
p1Data <- p1Data %>% rename(Event_type = `Reason.of.End.the.Study`)
p1Data$Event <- ifelse(p1Data$Event_type == "DEATH", 1, 0)
p1Data$Gender <- ifelse(p1Data$Gender == "M", 0,
ifelse(p1Data$Gender == "F", 1, NA))
summary(p1Data)
ggplot(p1Data, aes(x = as.factor(Event_type))) +
geom_bar(fill = "skyblue") +
labs(x = "Gender (0 = Male, 1 = Female)", y = "Frequency", title = "Gender Frequency") +
theme_minimal()
summary(p1Data)
ggplot(p1Data, aes(x = as.factor(Event_type))) +
geom_bar(fill = "skyblue") +
labs(x = "Reason", y = "Frequency", title = "Reason for the End of the Study") +
theme_minimal()
summary(p1Data)
ggplot(p1Data, aes(x = as.factor(Event_Type))) +
geom_bar(fill = "skyblue") +
labs(x = "Reason", y = "Frequency", title = "Reason for the End of the Study") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
summary(p1Data)
ggplot(p1Data, aes(x = as.factor(Event_type))) +
geom_bar(fill = "skyblue") +
labs(x = "Reason", y = "Frequency", title = "Reason for the End of the Study") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
